{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dda310b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 19 candidates, totalling 190 fits\n",
      "Métricas guardadas en ../files/output/metrics.json\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import gzip\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, median_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "\n",
    "# ---------------------------- 1. Funciones de Utilidad (IO/Directorio) ----------------------------\n",
    "\n",
    "def crear_directorios_base():\n",
    "    os.makedirs(\"../files/models\", exist_ok=True)\n",
    "    os.makedirs(\"../files/output\", exist_ok=True)\n",
    "\n",
    "def cargar_datos_fuente():\n",
    "    train_df = pd.read_csv(\"../files/input/train_data.csv.zip\", compression=\"zip\")\n",
    "    test_df = pd.read_csv(\"../files/input/test_data.csv.zip\", compression=\"zip\")\n",
    "    return train_df, test_df\n",
    "\n",
    "def guardar_modelo_comprimido(estimator, path=\"../files/models/model.pkl.gz\"):\n",
    "    crear_directorios_base()\n",
    "    with gzip.open(path, \"wb\") as f:\n",
    "        pickle.dump(estimator, f)\n",
    "\n",
    "def recuperar_modelo(path=\"../files/models/model.pkl.gz\"):\n",
    "    if not os.path.exists(path):\n",
    "        return None\n",
    "    with gzip.open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "# ---------------------------- 2. Funciones de Procesamiento de Datos ----------------------------\n",
    "\n",
    "def limpiar_dataframe(df):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    # Creación de característica 'Age' \n",
    "    # Asumiendo 2021 como el año base\n",
    "    df[\"Age\"] = 2021 - df[\"Year\"]\n",
    "\n",
    "    # Eliminación de columnas no deseadas\n",
    "    df = df.drop([\"Year\", \"Car_Name\"], axis=1, errors='ignore')\n",
    "\n",
    "    # Eliminar NaNs \n",
    "    df = df.dropna()\n",
    "\n",
    "    return df\n",
    "\n",
    "def obtener_splits_entrenamiento_prueba(train_df, test_df):\n",
    "    train_clean = limpiar_dataframe(train_df)\n",
    "    test_clean = limpiar_dataframe(test_df)\n",
    "\n",
    "    # Separación de variables \n",
    "    x_train = train_clean.drop(\"Present_Price\", axis=1)\n",
    "    y_train = train_clean[\"Present_Price\"]\n",
    "\n",
    "    x_test = test_clean.drop(\"Present_Price\", axis=1)\n",
    "    y_test = test_clean[\"Present_Price\"]\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "# ---------------------------- 3. Funciones de Componentes de ML (Pipeline / Grid Search) ----------------------------\n",
    "\n",
    "def construir_pipeline_completo(feature_columns):\n",
    "\n",
    "    # Definición de columnas \n",
    "    categorical_features = [\"Fuel_Type\", \"Selling_type\", \"Transmission\"]\n",
    "    numeric_features = [col for col in feature_columns if col not in categorical_features]\n",
    "\n",
    "    # Preprocesador\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            # Las numéricas se escalan con MinMaxScaler\n",
    "            (\"num\", MinMaxScaler(), numeric_features),\n",
    "            # Las categóricas se codifican con OHE\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
    "        ],\n",
    "    \n",
    "        remainder=MinMaxScaler(), \n",
    "    )\n",
    "\n",
    "    # Armado del pipeline \n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        # Función de puntuación para Regresión\n",
    "        (\"feature_selection\", SelectKBest(score_func=f_regression)), \n",
    "        (\"model\", LinearRegression())\n",
    "    ])\n",
    "\n",
    "    return pipeline\n",
    "\n",
    "def configurar_busqueda_grid(estimator, param_grid, cv=10):\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv,\n",
    "        scoring=\"neg_mean_absolute_error\", \n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        refit=True\n",
    "    )\n",
    "    return grid_search\n",
    "\n",
    "\n",
    "# ---------------------------- 4. Funciones de Entrenamiento y Validación ----------------------------\n",
    "\n",
    "def entrenar_y_comparar_modelos(grid_search):\n",
    "\n",
    "    train_df, test_df = cargar_datos_fuente()\n",
    "    x_train, y_train, x_test, y_test = obtener_splits_entrenamiento_prueba(train_df, test_df)\n",
    "\n",
    "    # Entrenar el modelo (GridSearchCV)\n",
    "    grid_search.fit(x_train, y_train)\n",
    "\n",
    "    # Guardar el mejor estimador\n",
    "    guardar_modelo_comprimido(grid_search)\n",
    "\n",
    "\n",
    "def ejecutar_entrenamiento_mlp():\n",
    "\n",
    "    train_df, test_df = cargar_datos_fuente()\n",
    "    x_train, y_train, x_test, y_test = obtener_splits_entrenamiento_prueba(train_df, test_df)\n",
    "\n",
    "    pipeline = construir_pipeline_completo(feature_columns=x_train.columns.tolist())\n",
    "\n",
    "    # Parámetros del Código Fuente\n",
    "    param_grid = {\"feature_selection__k\": list(range(1, 20))}\n",
    "    \n",
    "    # cv=10 como en el Código Fuente.\n",
    "    gs = configurar_busqueda_grid(estimator=pipeline, param_grid=param_grid, cv=10) \n",
    "    entrenar_y_comparar_modelos(gs)\n",
    "\n",
    "\n",
    "def validar_y_generar_metricas():\n",
    "\n",
    "    crear_directorios_base()\n",
    "    train_df, test_df = cargar_datos_fuente()\n",
    "    x_train, y_train, x_test, y_test = obtener_splits_entrenamiento_prueba(train_df, test_df)\n",
    "\n",
    "    # cargar modelo (gzip)\n",
    "    estimator = recuperar_modelo()\n",
    "    if estimator is None:\n",
    "        raise FileNotFoundError(\"No se encontró modelo en files/models/model.pkl.gz\")\n",
    "\n",
    "    # predicciones\n",
    "    y_train_pred = estimator.predict(x_train)\n",
    "    y_test_pred = estimator.predict(x_test)\n",
    "\n",
    "    metrics = []\n",
    "\n",
    "    # Métricas de entrenamiento (Regresión)\n",
    "    train_metrics = {\n",
    "        \"type\": \"metrics\",\n",
    "        \"dataset\": \"train\",\n",
    "        \"r2\": float(r2_score(y_train, y_train_pred)),\n",
    "        \"mse\": float(mean_squared_error(y_train, y_train_pred)),\n",
    "        \"mad\": float(median_absolute_error(y_train, y_train_pred)),\n",
    "    }\n",
    "    metrics.append(train_metrics)\n",
    "\n",
    "    # Métricas de prueba (Regresión)\n",
    "    test_metrics = {\n",
    "        \"type\": \"metrics\",\n",
    "        \"dataset\": \"test\",\n",
    "        \"r2\": float(r2_score(y_test, y_test_pred)),\n",
    "        \"mse\": float(mean_squared_error(y_test, y_test_pred)),\n",
    "        \"mad\": float(median_absolute_error(y_test, y_test_pred)),\n",
    "    }\n",
    "    metrics.append(test_metrics)\n",
    "\n",
    "    # guardar JSONL\n",
    "    out_path = \"../files/output/metrics.json\"\n",
    "    with open(out_path, \"w\") as f:\n",
    "        for m in metrics:\n",
    "            f.write(json.dumps(m) + \"\\n\")\n",
    "\n",
    "    print(f\"Métricas guardadas en {out_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # si se ejecuta el script, entrena y luego comprueba\n",
    "    crear_directorios_base()\n",
    "    ejecutar_entrenamiento_mlp() \n",
    "    validar_y_generar_metricas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
